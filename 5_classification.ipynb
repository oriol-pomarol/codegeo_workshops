{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b26640c-6bd6-4fb0-9144-d3e0dc56fdb2",
   "metadata": {},
   "source": [
    "# 4. Understanding Classification Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094522e-2280-4431-8976-fa97fb2ab366",
   "metadata": {},
   "source": [
    "In previous workshops, we focused on regression problems, learning how to predict continuous variables using methods like Random Forest and Neural Networks. Today, we will work on a different type of problem: **classification**. Specifically, we will use machine learning to predict a **sediment categorical characteristic**, based on its **location** and some **physical characteristics**.\n",
    "\n",
    "Our dataset comes from the Geological Survey of the Netherlands and contains descriptions of sediments from the North Sea. Today, we will use a small, pre-processed subset of the dataset, but you can download the full dataset (and many other geological datasets!) at  [DINOloket](https://www.dinoloket.nl/en/subsurface-data). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe0ced0-c747-4883-a1d1-64efaee74030",
   "metadata": {},
   "source": [
    "![DINOloket](images/5_DINOloket.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad673f-642b-41e5-bf00-5ee861f47897",
   "metadata": {},
   "source": [
    "## 4.1 Problem Definition\n",
    "\n",
    "In this workshop, we will use a dataset containing sample descriptions of sediments from the North Sea. When a sample is collected, the Geological Survey of the Netherlands (GDN as denoted in Dutch) follows a standard method to describe the sediment. Using this \"Standard Drill Description Method\" ([Standaard Boor Beschrijvingsmethode](https://www.grondwatertools.nl/sites/default/files/GDN_SBB-NITG-00-141-A-(3)_20161111.pdf)) the GDN aims to systematically capture multiple characteristics of the collected samples. This method does not only apply to marine sediments, but to any sample that is described by the GDN. Of course, some characteristics only apply to certain types of samples. \n",
    "\n",
    "While some of these descriptions can be made quickly, others require laboratory analysis, which is more time-consuming and resource-intensive. Today, we will try to predict one of the time-consuming measurements (i.e. **Medium sand size category**) based on **location** and some easy-to-describe **sediment properties**.\n",
    "\n",
    "The **Medium sand size category** corresponds to **7** different categories in our dataset based on the size sand size of the sample. This measurement only applies to samples described as sand and those that have a representative portion of sand admixture. \n",
    "\n",
    "| Class            | Sand Median (µm)     | Code  |\n",
    "|-------------------|----------------------|-------|\n",
    "| Extremely fine    | 63 ≤ x < 105           | ZUF   |\n",
    "| Very fine         | 105 ≤ x < 150          | ZZF   |\n",
    "| Moderately fine   | 150  ≤ x < 210          | ZMF   |\n",
    "| Moderately coarse | 210 ≤ x < 300          | ZMG   |\n",
    "| Very coarse       | 300 ≤ x < 420          | ZZG   |\n",
    "| Extremely coarse  | 420  ≤ x< 2000         | ZUG   |\n",
    "\n",
    "**Other categories (ABM = NEN209 and ONB)**:\n",
    "\n",
    "- Coarse category: 210 - < 2000 µm (ZGC)\n",
    "\n",
    "\n",
    "Below are the predictor variables and the target variable for this exercise. Note that the sediment properties (e.g., color, calcareous portion) are also classified according to the categories in the 'Standard Drill Description Method'. If you want more details about these features, refer to the [document](https://www.grondwatertools.nl/sites/default/files/GDN_SBB-NITG-00-141-A-(3)_20161111.pdf) (information in Dutch).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df14f73-2401-44ee-b423-804ff6e691c1",
   "metadata": {},
   "source": [
    "| Feature Name (English)       | Feature Name (Dutch)              | Explanation                                | Reference (Page) |\n",
    "|-------------------------------|------------------------------------|--------------------------------------------|------------------|\n",
    "| Sample ID                    | NITG.nr                           | Sample ID                                 |                  |\n",
    "| X coordinate                 | X.coordinaat                      | X coordinate (CRS:28892)                  |                  |\n",
    "| Y coordinate                 | Y.coordinaat                      | Y coordinate (CRS:28892)                  |                  |\n",
    "| Height with respect to NAP   | Maaiveldhoogte..m.tov.NAP         | Z coordinate (depth)                      |                  |\n",
    "| Color                        | Kleur                             | Color based [SBB format L4]               | 47               |\n",
    "| Calcareous portion           | Kalkgehalte                       | Calcareous content [SBB format L14]       | 75               |\n",
    "| Main soil type               | Hoofdgrondsoort                   | Main soil type based [SBB format L3.1]    | 35               |\n",
    "| Organic portion              | Organische Stof                   | Organic portion [SBB format: L9]          | 65               |\n",
    "| Sand median class            | Zandmediaanklasse                 | Sand median [SBB format: L7.2.1]          | 52               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3371fd28",
   "metadata": {},
   "source": [
    "## 5.2 Predicting probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc2cba3",
   "metadata": {},
   "source": [
    "Bridging the gap between regression and classification task might sound difficult, but it can be achieved with a few simple steps:\n",
    "\n",
    "1. **From class to number**: To be able to use our regression models to predict classes, we need to convert those to numbers. If the classification task is binary (only two possibilities) then this is as simple as using 1 and 0. For multi-class problems a single number is not enough, so we assign each class to a vector with the same size as the number of classes. These vectors are filled with 0s except in one position correspondig to the respective class, which is filled by a 1. This is why this approach is known as *one-hot encoding*.\n",
    "\n",
    "> **Attention**: You might be wondering why not to predict a single number and simply assign the additional classes to another value, for example to 2. This is actually a very bad idea as it would assume that your classes are ordered and would punish errors unevenly during training.\n",
    "\n",
    "2. **From number to probability**: In the previous step we converted our class to a number, but only to 1s or 0s, but our regressor models can only predict continuous numbers. The trick here, is that instead of directly predicting the class, we predict the probability of that particular class. To convert it to our binary outputs we set a *probability threshold*, usually 0.5, for deciding between the two. For multiple classes, we can simply take the one with highest probabilty.\n",
    "\n",
    "3. **From probability to regression**: The final step is how to make our regressor model only predict values (or vectors of values) between one and zero. For binary problems, this can be easily solved by applying the *sigmoid* function to the output of the regression model. For multi-class problems, there is another function called *softmax* that can be applied to our predicted vector to ensure that their components sum up to one, as we would expect from a set of probabilities.\n",
    "\n",
    "Let's see this concept in practice by training the simplest classifier available, the logistic regression. In this case, the regressor used for predicting the probabilities is a simple multi-linear regression. To get started, let's see how our output actually looks like, and transform it to a numerical value as we have explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc49a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the output to a binary number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b4cc1d",
   "metadata": {},
   "source": [
    "Perfect, now that we have our outputs as numbers, we can train the logistic regression model on our binary data. Once the training is complete, we can check the linear coefficients of such model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic regression model and train it with our data\n",
    "log_reg_binary = \n",
    "log_reg_binary.fit(X_train_binary, y_train_binary.ravel())\n",
    "\n",
    "# Print the coefficients of the linear regression model\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b8d4b",
   "metadata": {},
   "source": [
    "This already gives us very important information as to which variables are positively correlated with #OUTCOME# and which the opposite according to the sign of their coefficients.\n",
    "\n",
    "Now let's try to calculate what the prediction should be for the first point in the test set by following the steps that we introduced before - but now the other way around!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6899a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the predictors for the value we want to predict\n",
    "X = X_test_binary[0]\n",
    "\n",
    "# Calculate the output of the regression model\n",
    "regression_output = \n",
    "print()\n",
    "\n",
    "# Calculate the probability by using the sigmoid function\n",
    "probability = \n",
    "print()\n",
    "\n",
    "# Calculate the final class according to a predefined probability treshold\n",
    "probability_threshold = 0.5\n",
    "predicted_class = int(probability > probability_threshold)\n",
    "print()\n",
    "\n",
    "# Check that the logistic regression returns the same prediction\n",
    "log_reg_class = log_reg_binary.predict(X)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846285b",
   "metadata": {},
   "source": [
    "Great! Now that we understood how the prediction was made, let's use it on all the test data and test the effect of changing the probability threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a map of the test data classes\n",
    "\n",
    "\n",
    "# Plot a map of the predicted classes with a threshold of 0.25, 0.5 and 0.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6692ab6e",
   "metadata": {},
   "source": [
    "As you might have expected, as we increase the probability threshold we predict the class we assigned to 0 more often. Essentially, we require the model to be increasingly confident that the data corresponds to class 1 to classify it as such.\n",
    "\n",
    "It is best to tune the probability threshold to ensure that we don't overpredict one of the variables, especially if the data is imbalanced. Keep tuned for a future workshop on imbalanced data in particular if you are interested in the topic!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d94c9",
   "metadata": {},
   "source": [
    "## 5.3 Evaluating the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d7db8",
   "metadata": {},
   "source": [
    "### The confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90486ff3",
   "metadata": {},
   "source": [
    "The best way to visualize the results of a classifier model is through a \"confusion matrix\". This is nothing more than a table which columns indicate the classes predicted by the ML model and which rows are the actual classes from the data. This is what it looks like for a binary problem:\n",
    "\n",
    "| Class           | Predicted Positive         | Predicted Negative         |\n",
    "|------------------------|----------------------------|----------------------------|\n",
    "| **Actual Positive**        | **TP** (True Positive)     | **FN** (False Negative)    |\n",
    "| **Actual Negative**        | **FP** (False Positive)    | **TN** (True Negative)     |\n",
    "\n",
    "Although the two binary classes are usually referred to as \"positive\" and \"negative\", it can be any two type of classes, so negative does not necessarily imply \"bad\". In our case, for example, the classes refer to #INSERT BINARY CLASS DESCRIPTION#. Let's generate a confusion matrix with the predictions from our logistic model we trained before. This can be easily computed with the ```confusion_matrix``` function in ```sklearn.metrics```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4fa9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Make predictions with the logistic regression model for the test set\n",
    "y_pred_binary = log_reg_binary.predict(X_test_binary)\n",
    "\n",
    "\n",
    "# Create the confusion matrix with the logistic regression model predictions\n",
    "confusion_matrix(y_test_binary, y_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3315bee",
   "metadata": {},
   "source": [
    "While simply displaying the confusion matrix is already quite informative of model performance, sometimes we want to test on specific metrics. Many of the common metrics used to evaluate the performance of classifier models can actually be computed from the confusion matrix directly. Here are some examples:\n",
    "\n",
    "* **Accuracy**: Probably the best known classification metric, it evaluates the percentage of samples that were classified into the correct class.\n",
    "\n",
    "$$Accuracy = \\frac{TP+TN}{TP+FP+TN+FN}$$\n",
    "\n",
    "* **Precision**: A high precision indicates there were not many false alarms of a specific (in binary, the positive) class.\n",
    "\n",
    "$$Precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "* **Recall**: A high recall indicates that there were not many missed cases of a specific (in binary, the positive) class. \n",
    "\n",
    "$$Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "First, try to compute those metrics with pen and paper from the confusion matrix that we just saw. When you are done, you can compare your results with those obtained by using the corresponding Scikit-learn functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd792cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the logistic regression model\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test_binary, y_pred_binary)\n",
    "print(f\"The accuracy of the logistic regression model is: {accuracy}\")\n",
    "\n",
    "# Compute the precision of the logistic regression model\n",
    "precision = sklearn.metrics.precision_score(y_test_binary, y_pred_binary)\n",
    "print(f\"The precision of the logistic regression model is: {precision}\")\n",
    "\n",
    "# Compute the recall of the logistic regression model\n",
    "recall = sklearn.metrics.recall_score(y_test_binary, y_pred_binary)\n",
    "print(f\"The recall of the logistic regression model is: {recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce754b8",
   "metadata": {},
   "source": [
    "### A more balanced metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aa20b3",
   "metadata": {},
   "source": [
    "While accuracy is the most straightforward way to determine the performance of a classification model, it might not always be the most suitable. This is especially true when the data that is being predicted is imbalanced, that is, when we have many more instances of one class than the rest. Then, it is common that the classifier learns to predict in favour of the majority class, performing really poorly in the rest. For those cases, there is a better metric that we can use that combines both precision and recall to obtain a more balanced metric for performance, the *F1-score*.\n",
    "\n",
    "$$F1\\ score = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$$\n",
    "\n",
    "Let's compute both accuracy and F1-score for our current data, then introduce a class imbalance artificially and compare them again. Which of the two do you feel better relates to model performance, from what you can see in the confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22624aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the F1 score of the logistic regression model\n",
    "f1_score = sklearn.metrics.f1_score(y_test_binary, y_pred_binary)\n",
    "\n",
    "# Print both accuracy and F1 score\n",
    "print(f\"Accuracy: {accuracy} - F1 score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c07022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-assign classes to artificially unbalance the dataset\n",
    "\n",
    "# Train a new logistic regression model with the unbalanced dataset\n",
    "\n",
    "# Make predictions with the logistic regression model for the test set\n",
    "\n",
    "# Create the confusion matrix with the logistic regression model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf85b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy and F1 score of the logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b90d385",
   "metadata": {},
   "source": [
    "## 5.4 Multi-class tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e302950",
   "metadata": {},
   "source": [
    "### Predicting multiple classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871af20",
   "metadata": {},
   "source": [
    "While binary problems are relatively common, many times we would like to predict multiple classes. This is the case, for example, if we want to determine the sand grain size category from our soil data. In this case we also want to use a more powerful algorithm, so we will compare the results of artificial neural networks (ANN) with those of a random forest (RF). Let's start by using *one-hot encoding* to convert our classes to numerical vectors and then train our models. The random forest model can work fine with classes, so we do not need to encode our outputs for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92adeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding on the sand size data and print the results\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f7582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ANN and RF models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609cac03",
   "metadata": {},
   "source": [
    "Now that the models are trained, we can show the predictions on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519a2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a map of the test data classes\n",
    "\n",
    "\n",
    "# Plot a map of the predicted classes for both ANN and RF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a8709",
   "metadata": {},
   "source": [
    "### Generalizing the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe73ad",
   "metadata": {},
   "source": [
    "To evaluate the models we can use the same tools that we did for the binary problem with some slight differences. Let's see how the confusion matrix looks for this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205388f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f1de68",
   "metadata": {},
   "source": [
    "As we keep adding classes the confusion matrix gets more and more cluttered, increasing the usefulness of using metrics. All the metrix that we have seen previously can be generalized to multi-class problems, with some slight differences. For the accuracy, for example, we will simply need to sum all elements in the diagonal and divide by the total data sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de14e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy for each of the models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0ae66",
   "metadata": {},
   "source": [
    "Recall and precision are now defined for each class. In our example, we might be especially concerned about correctly classifying extremely fine-grained sands, since those can easily infiltrate in machinery that might be installed on these sites reducing their useful lifespan greatly. Which of the two variables should we then compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f9cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the recall of both models for the extremely fine grain size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bb73ab",
   "metadata": {},
   "source": [
    "## 4.4 Final remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4b874",
   "metadata": {},
   "source": [
    "In this workshop you have learnt the basics of how to tackle a classification task, from the output definition to training and of course evaluating your model. To cement this knowledge, try and use the same data but choose another variable as your target, for example the color. You can re-use some of the code above. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the predictor and target variables\n",
    "\n",
    "# Split between train and test sets\n",
    "\n",
    "# Train the classification model of your choice\n",
    "\n",
    "# Evaluate the model performance on the test set\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
